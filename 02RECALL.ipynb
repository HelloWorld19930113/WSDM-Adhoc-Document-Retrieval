{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cupy\n",
    "import cupyx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_hdf('cleaned2.h5', 'val')\n",
    "train = pd.read_hdf('cleaned2.h5', 'train')\n",
    "candid = pd.read_hdf('cleaned2.h5', 'candid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description_id': '001184',\n",
       " 'description_text': 'Thus, in addition to prospective motion-reduction techniques, retrospective QC remains necessary to rule out distortion due to motion artifacts (Blumenthal et al., [**##**]; Gedamu, 2011). ([**##**]) also found that there was a dose-dependent effect of motion artifacts and estimated GM volume loss, with mild motion associated with 4%, moderate motion associated with 7%, and severe motion associated with 27% reduction of total GM.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.iloc[9].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.feature_extraction.text import _document_frequency\n",
    "\n",
    "class BM25Transformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    use_idf : boolean, optional (default=True)\n",
    "    k1 : float, optional (default=2.0)\n",
    "    b : float, optional (default=0.75)\n",
    "    References\n",
    "    ----------\n",
    "    Okapi BM25: a non-binary model - Introduction to Information Retrieval\n",
    "    http://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html\n",
    "    \"\"\"\n",
    "    def __init__(self, use_idf=True, k1=2.0, b=0.75):\n",
    "        self.use_idf = use_idf\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : sparse matrix, [n_samples, n_features]\n",
    "            document-term matrix\n",
    "        \"\"\"\n",
    "        if not sp.issparse(X):\n",
    "            X = sp.csc_matrix(X)\n",
    "        if self.use_idf:\n",
    "            n_samples, n_features = X.shape\n",
    "            df = _document_frequency(X)\n",
    "            idf = np.log((n_samples - df + 0.5) / (df + 0.5))\n",
    "            self._idf_diag = sp.spdiags(idf, diags=0, m=n_features, n=n_features)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, copy=True):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : sparse matrix, [n_samples, n_features]\n",
    "            document-term matrix\n",
    "        copy : boolean, optional (default=True)\n",
    "        \"\"\"\n",
    "        if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
    "            # preserve float family dtype\n",
    "            X = sp.csr_matrix(X, copy=copy)\n",
    "        else:\n",
    "            # convert counts or binary occurrences to floats\n",
    "            X = sp.csr_matrix(X, dtype=np.float64, copy=copy)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Document length (number of terms) in each row\n",
    "        # Shape is (n_samples, 1)\n",
    "        dl = X.sum(axis=1)\n",
    "        # Number of non-zero elements in each row\n",
    "        # Shape is (n_samples, )\n",
    "        sz = X.indptr[1:] - X.indptr[0:-1]\n",
    "        # In each row, repeat `dl` for `sz` times\n",
    "        # Shape is (sum(sz), )\n",
    "        # Example\n",
    "        # -------\n",
    "        # dl = [4, 5, 6]\n",
    "        # sz = [1, 2, 3]\n",
    "        # rep = [4, 5, 5, 6, 6, 6]\n",
    "        rep = np.repeat(np.asarray(dl), sz)\n",
    "        # Average document length\n",
    "        # Scalar value\n",
    "        avgdl = np.average(dl)\n",
    "        # Compute BM25 score only for non-zero elements\n",
    "        data = X.data * (self.k1 + 1) / (X.data + self.k1 * (1 - self.b + self.b * rep / avgdl))\n",
    "        X = sp.csr_matrix((data, X.indices, X.indptr), shape=X.shape)\n",
    "\n",
    "        if self.use_idf:\n",
    "            check_is_fitted(self, '_idf_diag', 'idf vector is not fitted')\n",
    "\n",
    "            expected_n_features = self._idf_diag.shape[0]\n",
    "            if n_features != expected_n_features:\n",
    "                raise ValueError(\"Input has n_features=%d while the model\"\n",
    "                                 \" has been trained with n_features=%d\" % (\n",
    "                                     n_features, expected_n_features))\n",
    "            # *= doesn't work\n",
    "            X = X * self._idf_diag\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行两次 修改三个地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = val['description_text'] # change train or val!!!!\n",
    "doc = candid['title'] + '' + \\\n",
    "      candid['journal'] + '' + \\\n",
    "      candid['keywords'] + '' + \\\n",
    "      candid['abstract']\n",
    "all = pd.concat([doc, query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt_vectorizer = CountVectorizer().fit(all)\n",
    "cnt_all = cnt_vectorizer.transform(all)\n",
    "bm25 = BM25Transformer().fit(cnt_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dc2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "/home/dc2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n"
     ]
    }
   ],
   "source": [
    "cnt_query = cnt_vectorizer.transform(query)\n",
    "bm25_query = bm25.transform(cnt_query)\n",
    "\n",
    "cnt_doc = cnt_vectorizer.transform(doc)\n",
    "bm25_doc = bm25.transform(cnt_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n"
     ]
    }
   ],
   "source": [
    "def cal_bm25_rank():\n",
    "    ans = []\n",
    "    step = 150\n",
    "    with cupy.cuda.Device(0):\n",
    "        tf_bm25_doc = cupyx.scipy.sparse.csr_matrix(bm25_doc.T)\n",
    "        def cal_a_query(start,step=10,topk=1000,tf_bm25_doc=None):\n",
    "\n",
    "            tf_bm25_query = cupyx.scipy.sparse.csr_matrix(bm25_query[start:start+step,:])\n",
    "            c = tf_bm25_query * (tf_bm25_doc)\n",
    "\n",
    "            del tf_bm25_query\n",
    "\n",
    "            cupy._default_memory_pool.free_all_blocks()\n",
    "            c = cupy.argsort(-c.todense())[:,:topk]\n",
    "            d = cupy.asnumpy(c)\n",
    "            return d\n",
    "        for i in range(0, len(val), step): # change train or val!!!!\n",
    "            ans.append(cal_a_query(i, step, 10000, tf_bm25_doc))\n",
    "            if i % 3000 == 0:\n",
    "                print(i)\n",
    "    ret = np.vstack(ans)\n",
    "    return ret\n",
    "bm25_rank = cal_bm25_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34428, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_rank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_recall2.npy', bm25_rank) # change train or val!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
